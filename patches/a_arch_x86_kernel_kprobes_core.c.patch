diff --git a/arch/x86/kernel/kprobes/core.c b/arch/x86/kernel/kprobes/core.c
index d9d8d16..139e5a0 100644
--- a/arch/x86/kernel/kprobes/core.c
+++ b/arch/x86/kernel/kprobes/core.c
@@ -123,9 +123,12 @@ __synthesize_relative_insn(void *from, void *to, u8 op)
 		s32 raddr;
 	} __packed *insn;
 
-	insn = (struct __arch_relative_insn *)from;
+	insn = (struct __arch_relative_insn *)ktla_ktva((unsigned long)from);
+
+	pax_open_kernel();
 	insn->raddr = (s32)((long)(to) - ((long)(from) + 5));
 	insn->op = op;
+	pax_close_kernel();
 }
 
 /* Insert a jump instruction at address 'from', which jumps to address 'to'.*/
@@ -171,7 +171,7 @@ int can_boost(kprobe_opcode_t *opcodes, void *addr)
 	kprobe_opcode_t opcode;
 	kprobe_opcode_t *orig_opcodes = opcodes;
 
-	if (search_exception_tables((unsigned long)addr))
+	if (search_exception_tables(ktva_ktla((unsigned long)addr)))
 		return 0;	/* Page fault may occur on this address. */
 
 retry:
@@ -263,12 +266,12 @@ __recover_probed_insn(kprobe_opcode_t *buf, unsigned long addr)
 	 * Fortunately, we know that the original code is the ideal 5-byte
 	 * long NOP.
 	 */
-	memcpy(buf, (void *)addr, MAX_INSN_SIZE * sizeof(kprobe_opcode_t));
+	memcpy(buf, (void *)ktla_ktva(addr), MAX_INSN_SIZE * sizeof(kprobe_opcode_t));
 	if (faddr)
 		memcpy(buf, ideal_nops[NOP_ATOMIC5], 5);
 	else
 		buf[0] = kp->opcode;
-	return (unsigned long)buf;
+	return ktva_ktla((unsigned long)buf);
 }
 
 /*
@@ -370,7 +373,9 @@ int __copy_instruction(u8 *dest, u8 *src)
 	/* Another subsystem puts a breakpoint, failed to recover */
 	if (insn.opcode.bytes[0] == BREAKPOINT_INSTRUCTION)
 		return 0;
+	pax_open_kernel();
 	memcpy(dest, insn.kaddr, length);
+	pax_close_kernel();
 
 #ifdef CONFIG_X86_64
 	if (insn_rip_relative(&insn)) {
@@ -397,7 +402,9 @@ int __copy_instruction(u8 *dest, u8 *src)
 			return 0;
 		}
 		disp = (u8 *) dest + insn_offset_displacement(&insn);
+		pax_open_kernel();
 		*(s32 *) disp = (s32) newdisp;
+		pax_close_kernel();
 	}
 #endif
 	return length;
@@ -512,6 +519,7 @@ static nokprobe_inline void restore_btf(void)
 	}
 }
 
+#ifdef CONFIG_KRETPROBES
 void arch_prepare_kretprobe(struct kretprobe_instance *ri, struct pt_regs *regs)
 {
 	unsigned long *sara = stack_addr(regs);
@@ -522,6 +530,7 @@ void arch_prepare_kretprobe(struct kretprobe_instance *ri, struct pt_regs *regs)
 	*sara = (unsigned long) &kretprobe_trampoline;
 }
 NOKPROBE_SYMBOL(arch_prepare_kretprobe);
+#endif
 
 static void setup_singlestep(struct kprobe *p, struct pt_regs *regs,
 			     struct kprobe_ctlblk *kcb, int reenter)
@@ -539,7 +548,7 @@ static void setup_singlestep(struct kprobe *p, struct pt_regs *regs,
 		 * nor set current_kprobe, because it doesn't use single
 		 * stepping.
 		 */
-		regs->ip = (unsigned long)p->ainsn.insn;
+		regs->ip = ktva_ktla((unsigned long)p->ainsn.insn);
 		preempt_enable_no_resched();
 		return;
 	}
@@ -556,9 +565,9 @@ static void setup_singlestep(struct kprobe *p, struct pt_regs *regs,
 	regs->flags &= ~X86_EFLAGS_IF;
 	/* single step inline if the instruction is an int3 */
 	if (p->opcode == BREAKPOINT_INSTRUCTION)
-		regs->ip = (unsigned long)p->addr;
+		regs->ip = ktla_ktva((unsigned long)p->addr);
 	else
-		regs->ip = (unsigned long)p->ainsn.insn;
+		regs->ip = ktva_ktla((unsigned long)p->ainsn.insn);
 }
 NOKPROBE_SYMBOL(setup_singlestep);
 
@@ -643,7 +652,7 @@ int kprobe_int3_handler(struct pt_regs *regs)
 				setup_singlestep(p, regs, kcb, 0);
 			return 1;
 		}
-	} else if (*addr != BREAKPOINT_INSTRUCTION) {
+	} else if (*(kprobe_opcode_t *)ktla_ktva((unsigned long)addr) != BREAKPOINT_INSTRUCTION) {
 		/*
 		 * The breakpoint instruction was removed right
 		 * after we hit it.  Another cpu has removed
@@ -677,6 +686,9 @@ NOKPROBE_SYMBOL(kprobe_int3_handler);
 asm(
 	".global kretprobe_trampoline\n"
 	".type kretprobe_trampoline, @function\n"
+#ifdef CONFIG_PAX_RAP
+	".quad __rap_hash_ret_kretprobe_trampoline\n"
+#endif
 	"kretprobe_trampoline:\n"
 #ifdef CONFIG_X86_64
 	/* We don't bother saving the ss register */
@@ -684,16 +696,19 @@ asm(
 	"	pushfq\n"
 	SAVE_REGS_STRING
 	"	movq %rsp, %rdi\n"
-	"	call trampoline_handler\n"
+	"	"PAX_DIRECT_CALL("trampoline_handler") "\n"
 	/* Replace saved sp with true return address. */
 	"	movq %rax, 152(%rsp)\n"
 	RESTORE_REGS_STRING
 	"	popfq\n"
+#ifdef KERNEXEC_PLUGIN
+	"	btsq $63,(%rsp)\n"
+#endif
 #else
 	"	pushf\n"
 	SAVE_REGS_STRING
 	"	movl %esp, %eax\n"
-	"	call trampoline_handler\n"
+	"	"PAX_DIRECT_CALL("trampoline_handler") "\n"
 	/* Move flags to cs */
 	"	movl 56(%esp), %edx\n"
 	"	movl %edx, 52(%esp)\n"
@@ -830,7 +845,7 @@ static void resume_execution(struct kprobe *p, struct pt_regs *regs,
 			     struct kprobe_ctlblk *kcb)
 {
 	unsigned long *tos = stack_addr(regs);
-	unsigned long copy_ip = (unsigned long)p->ainsn.insn;
+	unsigned long copy_ip = ktva_ktla((unsigned long)p->ainsn.insn);
 	unsigned long orig_ip = (unsigned long)p->addr;
 	kprobe_opcode_t *insn = p->ainsn.insn;
 
@@ -1144,7 +1159,9 @@ int __init arch_init_kprobes(void)
 	return 0;
 }
 
+#ifdef CONFIG_KRETPROBES
 int arch_trampoline_kprobe(struct kprobe *p)
 {
 	return 0;
 }
+#endif

diff --git a/arch/x86/include/asm/page.h b/arch/x86/include/asm/page.h
index cf8f619..bbcf5e6 100644
--- a/arch/x86/include/asm/page.h
+++ b/arch/x86/include/asm/page.h
@@ -58,6 +58,8 @@ static inline void copy_user_page(void *to, void *from, unsigned long vaddr,
 #define __va(x)			((void *)((unsigned long)(x)+PAGE_OFFSET))
 #endif
 
+#define __early_va(x)		((void *)((unsigned long)(x)+__START_KERNEL_map - phys_base))
+
 #define __boot_va(x)		__va(x)
 #define __boot_pa(x)		__pa(x)
 
@@ -65,11 +67,21 @@ static inline void copy_user_page(void *to, void *from, unsigned long vaddr,
  * virt_to_page(kaddr) returns a valid pointer if and only if
  * virt_addr_valid(kaddr) returns true.
  */
-#define virt_to_page(kaddr)	pfn_to_page(__pa(kaddr) >> PAGE_SHIFT)
 #define pfn_to_kaddr(pfn)      __va((pfn) << PAGE_SHIFT)
 extern bool __virt_addr_valid(unsigned long kaddr);
 #define virt_addr_valid(kaddr)	__virt_addr_valid((unsigned long) (kaddr))
 
+#ifdef CONFIG_GRKERNSEC_KSTACKOVERFLOW
+#define virt_to_page(kaddr)	\
+	({ \
+		const void *__kaddr = (const void *)(kaddr); \
+		BUG_ON(!virt_addr_valid(__kaddr)); \
+		pfn_to_page(__pa(__kaddr) >> PAGE_SHIFT); \
+	})
+#else
+#define virt_to_page(kaddr)	pfn_to_page(__pa(kaddr) >> PAGE_SHIFT)
+#endif
+
 #endif	/* __ASSEMBLY__ */
 
 #include <asm-generic/memory_model.h>

diff --git a/include/linux/atomic.h b/include/linux/atomic.h
index e71835b..957f2d6 100644
--- a/include/linux/atomic.h
+++ b/include/linux/atomic.h
@@ -72,6 +72,7 @@
 #define  atomic_add_return_relaxed	atomic_add_return
 #define  atomic_add_return_acquire	atomic_add_return
 #define  atomic_add_return_release	atomic_add_return
+#define atomic_add_return_unchecked_relaxed	atomic_add_return_unchecked
 
 #else /* atomic_add_return_relaxed */
 
@@ -89,6 +90,11 @@
 #define  atomic_add_return(...)						\
 	__atomic_op_fence(atomic_add_return, __VA_ARGS__)
 #endif
+
+#ifndef atomic_add_return_unchecked
+#define  atomic_add_return_unchecked(...)				\
+	__atomic_op_fence(atomic_add_return_unchecked, __VA_ARGS__)
+#endif
 #endif /* atomic_add_return_relaxed */
 
 /* atomic_inc_return_relaxed */
@@ -113,6 +119,11 @@
 #define  atomic_inc_return(...)						\
 	__atomic_op_fence(atomic_inc_return, __VA_ARGS__)
 #endif
+
+#ifndef atomic_inc_return_unchecked
+#define  atomic_inc_return_unchecked(...)				\
+	__atomic_op_fence(atomic_inc_return_unchecked, __VA_ARGS__)
+#endif
 #endif /* atomic_inc_return_relaxed */
 
 /* atomic_sub_return_relaxed */
@@ -490,6 +501,10 @@
 #ifndef xchg
 #define  xchg(...)			__atomic_op_fence(xchg, __VA_ARGS__)
 #endif
+
+#ifndef xchg_unchecked
+#define  xchg_unchecked(...)		__atomic_op_fence(xchg_unchecked, __VA_ARGS__)
+#endif
 #endif /* xchg_relaxed */
 
 /**
@@ -501,7 +516,7 @@
  * Atomically adds @a to @v, so long as @v was not already @u.
  * Returns non-zero if @v was not @u, and zero otherwise.
  */
-static inline int atomic_add_unless(atomic_t *v, int a, int u)
+static inline int __intentional_overflow(-1) atomic_add_unless(atomic_t *v, int a, int u)
 {
 	return __atomic_add_unless(v, a, u) != u;
 }
@@ -618,7 +633,7 @@ static inline int atomic_dec_if_positive(atomic_t *v)
 		dec = c - 1;
 		if (unlikely(dec < 0))
 			break;
-		old = atomic_cmpxchg((v), c, dec);
+		old = atomic_cmpxchg(v, c, dec);
 		if (likely(old == c))
 			break;
 		c = old;
@@ -661,6 +676,11 @@ static inline int atomic_dec_if_positive(atomic_t *v)
 #define  atomic64_add_return(...)					\
 	__atomic_op_fence(atomic64_add_return, __VA_ARGS__)
 #endif
+
+#ifndef atomic64_add_return_unchecked
+#define  atomic64_add_return_unchecked(...)				\
+	__atomic_op_fence(atomic64_add_return_unchecked, __VA_ARGS__)
+#endif
 #endif /* atomic64_add_return_relaxed */
 
 /* atomic64_inc_return_relaxed */
@@ -685,6 +705,11 @@ static inline int atomic_dec_if_positive(atomic_t *v)
 #define  atomic64_inc_return(...)					\
 	__atomic_op_fence(atomic64_inc_return, __VA_ARGS__)
 #endif
+
+#ifndef atomic64_inc_return_unchecked
+#define  atomic64_inc_return_unchecked(...)				\
+	__atomic_op_fence(atomic64_inc_return_unchecked, __VA_ARGS__)
+#endif
 #endif /* atomic64_inc_return_relaxed */
 
 
@@ -970,6 +995,11 @@ static inline int atomic_dec_if_positive(atomic_t *v)
 #define  atomic64_xchg(...)						\
 	__atomic_op_fence(atomic64_xchg, __VA_ARGS__)
 #endif
+
+#ifndef atomic64_xchg_unchecked
+#define  atomic64_xchg_unchecked(...)					\
+	__atomic_op_fence(atomic64_xchg_unchecked, __VA_ARGS__)
+#endif
 #endif /* atomic64_xchg_relaxed */
 
 /* atomic64_cmpxchg_relaxed */
@@ -994,6 +1024,11 @@ static inline int atomic_dec_if_positive(atomic_t *v)
 #define  atomic64_cmpxchg(...)						\
 	__atomic_op_fence(atomic64_cmpxchg, __VA_ARGS__)
 #endif
+
+#ifndef atomic64_cmpxchg_unchecked
+#define  atomic64_cmpxchg_unchecked(...)				\
+	__atomic_op_fence(atomic64_cmpxchg_unchecked, __VA_ARGS__)
+#endif
 #endif /* atomic64_cmpxchg_relaxed */
 
 #ifndef atomic64_andnot
